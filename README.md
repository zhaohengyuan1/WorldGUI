

<div align="center">
  <img style="width: 100%" src="./assets/title.jpg">
</div>

<details>
<summary style="font-size:18px">‚ú® What's new in GUI-Thinker?</summary>

<!-- ## ‚ú® What's new in GUI-Thinker? -->

**GUI-Thinker** is a newly developed GUI agent based on a self-reflection mechanism. We systematically investigate GUI automation and establish the following workflow, incorporating three key self-reflection modules:

- Planner-Critic (Post-Planning Critique): Self-corrects the initial plans to ensure their accuracy

- Step-Check (Pre-Execution Validation): Remove redundant steps or modify them if necessary.

- Actor-Critic (Post-Action Evaluation): Review the task completion status and apply necessary corrections.



<p align="center" style="margin:0"><img src="./assets/agentoverview.jpg" alt="agent" style="width: 80%" /></p>

<p align="center">Figure 1: Overview of GUI-Thinker.</p>

<p align="center" style="margin:0"><img src="./assets/com_barchart.png" alt="results" style="width: 80%" /></p>

<p align="center">Figure 2: Comparison of various agents on the WorldGUI Benchmark (meta task).</p>

</details>


## ‚ú®Key Features

- üèÜ **High Performance**: Our GUI-Thinker surpasses Cluade-3.5 Computer Use by 14.9% on our WorldGUI Benchmark.
- üåê **Universal LMM Support**: Seamlessly integrates with **A Wide Range** of LMMs (e.g., OpenAI, Anthropic, Gemini)
- üîÄ **Flexible Interaction**: Supports both **intructional video input** and **non-instructional video input**.
- üöÄ **Easy Deployment**:  Get started instantly with a simple `.\shells\start_server.bat` command and `python test_guithinker_custom.py` without the need of Docker or Virtual Machine.


## ü§ñ Core Components:
Our codebases includes:

- [x] **GUI Parser:** Utilizes Google OCR and PyAutoGUI to extract element grounding information.
- [x] **State-Aware Planner:** Accepts screenshots and instructional videos to generate plans.
- [x] **Planner-Critic:** Refines the initial plan generated by the planner.
- [x] **Step-Check:** Verifies task completion and redundancy using various output statuses (e.g., `<Modify>`, `<Pass>`, `<Continue>`, `<Finished>`). It also implements an LLM-driven region search module to locate target elements.
- [x] **Actor:** Translates action descriptions into executable code (e.g., `click(100, 200)`).
- [x] **Actor-Critic:** Checks task completion status by comparing before and after screenshots and uses an iterative action correction algorithm to gradually verify and correct actions.
- [x] **Input with Instructional Video:** Supports the execution with instructional video.
- [x] **Input without Instructional Video:** Supports the direct execution with user query.


See our [paper](https://arxiv.org/abs/2502.08047) for detail. Our GUI-Thinker is along with a newly curted Desktop GUI benchmark WorldGUI.

## ‚úÖ Todo List

GUI-Thinker is continuously evolving! Here's what's coming:

- üñ•Ô∏è **Lightweight Version**: Supporting a lightweight version specially design for Claude-3.5-Sonnet Computer Use without the GUI parser.

- üëì **OOTB Usage**: Supporting a user-frendly interface based on Gradio.

- üìä **Locally-running Models**: Supporting the ShowUI or UI-TARS as the Actor in our framework.

- üé® **Huggingface Demo**: Developing online demo in Huggingface.

Feel free to open issues or submit pull requests if you have suggestions. Our project is actively maintained, with new features and bug fixes released regularly. üöÄ


## üñ•Ô∏è Demo of Computer Using

Demo Video (The video has been sped up):

https://github.com/user-attachments/assets/5d25c079-4c84-4435-8280-591f32f89700


## üöÄ Getting Started


## 1. Clone the Repository üìÇ
Open the Conda Terminal. (After installation Of Miniconda, it will appear in the Start menu.)
Run the following command on **Conda Terminal**.
```bash
git clone https://github.com/showlab/GUI-Thinker.git
cd GUI-Thinker
```

## 2. Env setup üî®

To create a Conda virtual environment and activate it, follow these steps:

Create a new Conda environment named `guithinker` with Python 3.11 installed:

```bash
conda create -n guithinker python=3.11
conda activate guithinker
pip install -r requirements.txt
```

Install the dependencies:
```bash
pip install -r requirements.txt
```
Moreover, you can refer to the files under folder `.log` to manually install the corresponding modules.

## 3. Set API Key ‚úèÔ∏è
We recommend running one or more of the following command to set API keys to the environment variables. On Windows Powershell (via the set command if on cmd):

>```bash
>$env:ANTHROPIC_API_KEY="sk-xxxxx" (Replace with your own key)
>$env:GEMINI_API_KEY="sk-xxxxx"
>$env:OPENAI_API_KEY="sk-xxxxx"
>```

## 4. Set Google Clound Vision API üîß
We implement our GUI parser with the help of [google clound vision service](https://cloud.google.com/vision?hl=zh_cn). We recommend you following this [guidance](https://cloud.google.com/vision/product-search/docs/auth?hl=zh-cn) to save a local file for the identity verification.

```bash
gcloud auth activate-service-account --key-file KEY_FILE

$env:GOOGLE_APPLICATION_CREDENTIALS="PATH_TO_KEY_FILE"
```

(Optional) Set the path of `KEY_FILE` in the path [agent/gui_parser/server.py#L18](https://github.com/showlab/WorldGUI/blob/main/agent/gui_parser/server.py#L18)

## 5. Quick Start ‚≠ê

Start with your own query or included query in folder `data`.

### 5.1 Start the server

We implemented a backend and frontend system that separates screenshot capture from agent execution, enabling remote deployment of the agent via API calls. The frontend can run on Windows or other platforms (e.g., mobile devices).

For windows:
```bash
.\shells\start_server.bat
```
You can track the status by checking the files under folder `.log`. Every time you change the files under the folder **`agent`**, you need to restart the server.

### Restart the server

For windows:
```bash
.\shells\end_server.bat
.\shells\start_server.bat
```
### üéà 5.2 Test with your own user query

Here, we provide a straightforward example demonstrating how to operate a YouTube video using the Claude-3.5-Sonnet as the base model. Check the configuration of file `agent\config\basic.yaml` to edit the base model.

Command:
```bash
python test_guithinker_custom.py --userquery "Open the video "https://www.youtube.com/watch?v=uTuuz__8gUM", add to watch later and create a watch list 'work & jazz'." --projfile_path "" --software_name "Youtube"
```

<!-- Demo Video (The video has been sped up):

https://github.com/user-attachments/assets/5d25c079-4c84-4435-8280-591f32f89700

See 1080p version from https://www.youtube.com/watch?v=RoJ-cbjfZmg -->

Initial Screenshot:
<p align="left"><img src="./assets/step0.png" alt="" style="width: 70%"/></p>

(Milestone 1) Task 1: Add video to Watch Later 

Subtask 1: Click on "More actions" button [1231, 936]
<p align="left"><img src="./assets/step1.png" alt="" style="width: 70%"/></p>
Subtask 2: Click on "Save" option in the menu that appears
<p align="left"><img src="./assets/step2.png" alt="" style="width: 70%"/></p>
Subtask 3: Click on "Watch Later" option in the save menu
<p align="left"><img src="./assets/step3.png" alt="" style="width: 70%"/></p>

(Milestone 2) Task 2: Create new playlist "work & jazz" 

Subtask 1: Click on "More actions" button again if the menu closed

Output of Step-Check: `<Pass>`. Therefore no change in current step. (See the deatail design of Step-Check from [paper](https://arxiv.org/abs/2502.08047))

<p align="left"><img src="./assets/step4.png" alt="" style="width: 70%"/></p>

Subtask 2: Click on "Save" option if the save menu is not open

Output of Step-Check: `<Pass>`. Therefore no change in current step.
<p align="left"><img src="./assets/step5.png" alt="" style="width: 70%"/></p>

Subtask 3: Click on "+ Create new playlist" option at the bottom of the save menu
<p align="left"><img src="./assets/step6.png" alt="" style="width: 70%"/></p>

Subtask 4: Type "work & jazz" in the playlist name field
<p align="left"><img src="./assets/step7.png" alt="" style="width: 70%"/></p>

Subtask 5: Click "Create" button to confirm the new playlist creation
<p align="left"><img src="./assets/step8.png" alt="" style="width: 70%"/></p>


### üíª 5.3 Test with a simple demo case under the folder `data`:
```bash
python test_guithinker_demo.py
``` 

User Query: Select all text and apply numbered list for them. Use '1, 2, 3' symbol of numbered list.

Initial Screenshot:
<p align="left"><img src="./assets/demo_start.png" alt="" style="width: 70%"/></p>

Intermediate Screenshot:
<p align="left"><img src="./assets/demo_inter.png" alt="" style="width: 70%"/></p>

Invoke the *Region Search* component in the Step-Check Module, which yields the following image:
<p align="left"><img src="./assets/region_locate.png" alt="" style="width: 70%"/></p>

Reducing the resolution and directing the agent's focus toward highly relevant regions will enhance its critique decisions.

Final Screenshot:
<p align="left"><img src="./assets/demo_end.png" alt="" style="width: 70%"/></p>